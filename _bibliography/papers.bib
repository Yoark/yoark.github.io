---
---

@article{zijiao2022behave,
  abbr     = {CVPR},
  title    = {Behavioral Analysis of Vision-and-Language Navigation Agents},
  author   = {Yang, Zijiao and Majumdar, Arjun and Lee, Stefan},
  abstract = {To be successful, Vision-and-Language Navigation (VLN) agents must be able to ground instructions to actions based on their surroundings. In this work, we develop a methodology to study agent behavior on a skill-specific basis -- examining how well existing agents ground instructions about stopping, turning, and moving towards specified objects or rooms. Our approach is based on generating skill-specific interventions and measuring changes in agent predictions. We present a detailed case study analyzing the behavior of a recent agent and then compare multiple agents in terms of skill-specific competency scores. This analysis suggests that biases from training have lasting effects on agent behavior and existing models have grounding simple referring expressions. Our comparisons between models shows that skill-specific scores correlate with improvements in overall VLN task performance.},
  selected = {true},
  html     = {/paper_sites/vln-behave/},
  journal  = {Computer Vision and Pattern Recognition},
  year     = {2023},
  date = {2023-06-18},
  pdf      = {vln-behave/vln-behave.pdf}
}
@article{yang2024hijackingvisionandlanguagenavigationagents,
      abbr={WACV},
      title={Hijacking Vision-and-Language Navigation Agents with Adversarial Environmental Attacks}, 
      author={Zijiao Yang and Xiangxi Shi and Eric Slyman and Stefan Lee},
      abstract={Assistive embodied agents that can be instructed in natural language to perform tasks in open-world environments have the potential to significantly impact labor tasks like manufacturing or in-home care -- benefiting the lives of those who come to depend on them. In this work, we consider how this benefit might be hijacked by local modifications in the appearance of the agent's operating environment. Specifically, we take the popular Vision-and-Language Navigation (VLN) task as a representative setting and develop a whitebox adversarial attack that optimizes a 3D attack object's appearance to induce desired behaviors in pretrained VLN agents that observe it in the environment. We demonstrate that the proposed attack can cause VLN agents to ignore their instructions and execute alternative actions after encountering the attack object -- even for instructions and agent paths not considered when optimizing the attack. For these novel settings, we find our attacks can induce early-termination behaviors or divert an agent along an attacker-defined multi-step trajectory. Under both conditions, environmental attacks significantly reduce agent capabilities to successfully follow user instructions.},
      selected={true},
      journal={IEEE/CVF Winter Conference on Applications of Computer Vision},
      year={2025},
      date={2025-02-28},
      pdf={hijack_vln/hijack_vln.pdf}
}